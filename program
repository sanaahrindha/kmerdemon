import argparse
import random

def parse_fastq(file_path, out_file): #parse a fastq file and return the number of reads and write reads to output file
    with open(file_path, 'r') as file1, open(out_file, "w") as file2:
        num_reads = 0
        lines = file1.readlines()
        for line in lines:
            if line.startswith('@'):
                file2.write(line[1:])
                num_reads += 1
    return num_reads

def make_kmers(read, kmer_size): # returns list of kmers given a read
    kmers = [len(read)-kmer_size+1]
    for i in range(len(kmers)):
        kmers[i] = read[i:i+kmer_size]


def abundance(parsed_file, threshold, size): #given parsed file from parse_fastq() create subset of reads to analyze
    reads = []
    kmer_frequencies = {}
    # open file, select proportion of reads to analyze
    with open(parsed_file, "r") as file1:
        lines = file1.readlines()
        for line in lines:
            rand = random.random()
            if rand < threshold:
                reads.append(line) 
    # count frequencies of every kmer in each read
    for read in reads:
        kmers = make_kmers(read, size)
        for kmer in kmers:
            if kmer not in kmer_frequencies:
                kmer_frequencies[kmer] = 1
            else: 
                kmer_frequencies[kmer] += 1
    return kmer_frequencies  

def estimate_genome_size(num_unique_kmers, kmer_size, coverage): #estimate size of genome after looking at the number of kmers, kmer size, and coverage
    estimated_genome_size = num_unique_kmers * kmer_size / coverage
    return estimated_genome_size

def main_function():
    parser = argparse.ArgumentParser(description=)"Tool to estimate optimal genome and k-mer size" #tool description 
    parser.add.argument("input files", nargs="+", help="Input FASTQ files") #input file(s)
    parser.add.argument("--min_kmer_size", type=int, default=15, help="Minimum k-mer length for analysis") #optional, default set
    parser.add.argument("--max_kmer_size", type=int, default=120, help="Maximum k-mer length for analysis") #optional, default set
    parser.add_argument("--kmer_sampling_proportion", type=float, default=0.1, help="Proportion of k-mers to sample") #optional, default set
    parser.add.argument("--output_prefix", default="output", help="Prefix for output files") #optional, idk if needed
    args = parser.parse_args() #process arguments

    num_reads = 0
    for file_path in args.input_files:
        num_reads += parse_fastq(file_path) #parse input files 

    #still need to perform analysis/estimate size

        output_file = f"{args.output_prefix}_kmer_{kmer_size}.txt"
        with open(output_file, 'w') as output_file:
            output_file.write(f"K-mer Size: {kmer_size}\n")
            output_file.write(f"Number of Unique K-mers: {num_unique_kmers}\n")
            output_file.write(f"Estimated Genome Size: {estimated_genome_size}\n")


    

python kmer_estimator.py input1.fastq input2.fastq --min_kmer_size 15 --max_kmer_size 120 --output_prefix myoutput
