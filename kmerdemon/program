import argparse
import random
import matplotlib.pyplot as plt
from collections import defaultdict
import os

def parse_fastq(file_path, out_file): #parse a fastq file and return the number of reads and write reads to output file
    with open(file_path, 'r') as file1, open(out_file, "w") as file2:
        num_reads = 0
        lines = file1.readlines()
        for line in lines:
            if line.startswith('@'):
                file2.write(line[1:])
                num_reads += 1
    return num_reads

def make_kmers(read, kmer_size): # returns list of kmers given a read
    kmers = [0]*(len(read)-kmer_size+1)
    #print(len(kmers))
    for i in range(len(kmers)):
        kmers[i] = read[i:i+kmer_size]
    #print(kmers)
    return kmers


def abundance(parsed_file, threshold, size): #given parsed file from parse_fastq() create subset of reads to analyze
    reads = []
    kmer_frequencies = {}
    # open file, select proportion of reads to analyze
    with open(parsed_file, "r") as file1:
        lines = file1.readlines()
        #print(len(lines))
        for line in lines:
            rand = random.random()
            if rand < threshold:
                reads.append(line.strip()) 
    # count frequencies of every kmer in each read
    #print(len(reads))
    for read in reads:
        kmers = make_kmers(read, size)
        #print(kmers)
        for kmer in kmers:
            if kmer not in kmer_frequencies:
                kmer_frequencies[kmer] = 1
            else: 
                kmer_frequencies[kmer] += 1
    print(len(kmer_frequencies))
    return kmer_frequencies 

def estimate_genome_size(num_unique_kmers, kmer_size, coverage): #estimate size of genome after looking at the number of kmers, kmer size, and coverage
    estimated_genome_size = num_unique_kmers * kmer_size / coverage
    return estimated_genome_size


def create_histogram(kmer_counts, k):
    histogram = defaultdict(int)
    for count in kmer_counts.values():
        histogram[count] += 1
    plot_histogram(histogram, k)
    
def plot_histogram(histogram, k):                   # This should be fine for now, after inspecting the output may change to incorporate Gaussian KDE /redline
    abundances = sorted(histogram.keys())
    frequencies = [histogram[a] for a in abundances]
    plt.figure(figsize=(10,6))
    plt.bar(abundances, frequencies, width=1.0, edgecolor="black")
    plt.xlabel('K-mer Abundance')
    plt.ylabel('Frequency')
    plt.title(f'K-mer Abundance Histogram for k={k}')
    plt.yscale('log')
    plt.savefig(f'kmer_histogram_k{k}.png')
    plt.close()

def predict_best_k(histograms):
    best_k = max(histograms, key=lambda k: sum(histograms[k].values()))
    return best_k

"""
def predict_best_k(histograms):
    best_k = None
    max_unique_kmers = 0
    for k, histogram in histograms.items():
        unique_kmers = sum(histogram.values())
        if unique_kmers > max_unique_kmers:
            max_unique_kmers = unique_kmers
            best_k = k
    return best_k
"""


def main_function():
    parser = argparse.ArgumentParser(prog="kmerdemon", description="Tool to estimate optimal genome and k-mer size") #tool description 
    parser.add_argument("input files", nargs="+", help="Input FASTQ files") #input file(s)
    parser.add_argument("--min_kmer_size", type=int, default=15, help="Minimum k-mer length for analysis") #optional, default set
    parser.add_argument("--max_kmer_size", type=int, default=120, help="Maximum k-mer length for analysis") #optional, default set
    parser.add_argument("--kmer_sampling_proportion", type=float, default=0.1, help="Proportion of k-mers to sample") #optional, default set
    parser.add_argument("--output_prefix", default="output", help="Prefix for output files") #optional, idk if needed
    args = parser.parse_args() #process arguments

    num_reads = 0
    for file_path in args.input_files:
        num_reads += parse_fastq(file_path, "{file_path}_parsed.txt") #parse input files 

    increment = int((args.max_kmer_size - args.min_kmer_size)/10)
    kmer_frequencies_by_size = {}
    # get abundance data for each kmer size in range from min to max, add to dictionary
    # keep track of optimal kmer length
    max_unique_kmers = 0
    optimal_kmer_length = -1
    for kmer_size in range(args.min_kmer_size, args.max_kmer_size, increment):
        kmer_frequencies_by_size[kmer_size] = abundance("{file_path}_parsed.txt",args.kmer_sampling_proportion,kmer_size)
        if len(kmer_frequencies_by_size[kmer_size]) > max_unique_kmers:
            max_unique_kmers = len(kmer_frequencies_by_size[kmer_size])
            optimal_kmer_length = kmer_size

    for kmer_size in range(optimal_kmer_length-5, optimal_kmer_length+5, 2):
            

    #still need to perform analysis/estimate size

        output_file = f"{args.output_prefix}_kmer_{kmer_size}.txt"
        with open(output_file, 'w') as output_file:
            output_file.write(f"K-mer Size: {kmer_size}\n")
            output_file.write(f"Number of Unique K-mers: {num_unique_kmers}\n")
            output_file.write(f"Estimated Genome Size: {estimated_genome_size}\n")

if __name__ == "__main__":
    main_function()
    

#python kmer_estimator.py input1.fastq input2.fastq --min_kmer_size 15 --max_kmer_size 120 --output_prefix myoutput
